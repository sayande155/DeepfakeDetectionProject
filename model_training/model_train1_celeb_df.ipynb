{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# IMPORTS\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","from torch.utils.data import Dataset, DataLoader\n","import cv2\n","import numpy as np\n","import os\n","from glob import glob\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import random\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from efficientnet_pytorch import EfficientNet\n","from sklearn.model_selection import train_test_split\n","import json"],"metadata":{"id":"07sWw7ltohab","executionInfo":{"status":"ok","timestamp":1754369701611,"user_tz":-330,"elapsed":4,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# ! pip install efficientnet_pytorch"],"metadata":{"collapsed":true,"id":"B6Kunytm2JoJ","executionInfo":{"status":"ok","timestamp":1754369702321,"user_tz":-330,"elapsed":2,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Running on\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnvNJyvd2ogf","executionInfo":{"status":"ok","timestamp":1754369703258,"user_tz":-330,"elapsed":24,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"outputId":"365a97b2-b070-4c6c-f2bd-8c46f93c638f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on cuda\n"]}]},{"cell_type":"code","source":["torch.cuda.get_device_name(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"euKi_pc72pXP","executionInfo":{"status":"ok","timestamp":1754369704080,"user_tz":-330,"elapsed":23,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"outputId":"5eb8b91d-86f8-42e7-ff2d-65589403f5ac"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Tesla T4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["import torch\n","print(torch.__version__)\n","print(torch.version.cuda)\n","print(torch.cuda.is_available())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIZThCKs2zBG","executionInfo":{"status":"ok","timestamp":1754369704803,"user_tz":-330,"elapsed":11,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"outputId":"7bde7895-55e3-4591-bb07-e0ec5c9a1c50"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2.6.0+cu124\n","12.4\n","True\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-wJe7DPnA4V","executionInfo":{"status":"ok","timestamp":1754369708800,"user_tz":-330,"elapsed":1865,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"outputId":"26a7a24d-3196-4452-80db-345d72ddba3a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# mount drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Load and validate videos\n","def frame_extract(path):\n","    video = cv2.VideoCapture(path)\n","    success = True\n","    while success:\n","        success, image = video.read()\n","        if success:\n","            yield image\n","\n","    video.release()\n","\n","# Validate video by trying to extract and transform 20 frames.\n","\n","\n","def validate_video(video_path, transform, count=20):\n","    all_frames = [frame for frame in frame_extract(video_path) if frame is not None]\n","\n","    if len(all_frames) < count:\n","        raise ValueError(f\"Not enough frames in video: {video_path} (Found {len(all_frames)})\")\n","\n","    selected_frames = random.sample(all_frames, count)\n","\n","    transformed_frames = [transform(frame) for frame in selected_frames]\n","    frames_tensor = torch.stack(transformed_frames)\n","\n","    return frames_tensor\n","\n","# parameters\n","image_size = 224\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","train_transforms = T.Compose(\n","    [\n","        T.ToPILImage(),\n","        T.Resize((image_size, image_size)),\n","        T.ToTensor(),\n","        T.Normalize(mean, std)\n","    ]\n",")\n"],"metadata":{"id":"03mi-Xue24hv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !find \"/content/drive/My Drive\" -name \"*celeb_df_face_cropped*\"\n","# !ls \"/content/drive/My Drive/\"\n"],"metadata":{"id":"r1lFGuSL4KbH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DATASET FETCH\n","\n","# Paths to real and fake video folders on Google Drive\n","celeb_df_real_path = '/content/drive/My Drive/celeb_df_face_cropped/real_face_only224'\n","celeb_df_fake_path = '/content/drive/My Drive/celeb_df_face_cropped/fake_face_only224'\n","\n","# Get all .mp4 file paths\n","real_videos = sorted(glob(f\"{celeb_df_real_path}/*.mp4\"))\n","fake_videos = sorted(glob(f\"{celeb_df_fake_path}/*.mp4\"))"],"metadata":{"id":"wT0MJsWNnjcM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Total Real Videos: {len(real_videos)}\")\n","print(f\"Total Fake Videos: {len(fake_videos)}\")\n","# print(\"Sample real video:\", real_videos[0] if real_videos else \"None\")\n","# print(\"Sample fake video:\", fake_videos[0] if fake_videos else \"None\")\n"],"metadata":{"id":"nqMfK4GgoXHg","executionInfo":{"status":"ok","timestamp":1754341261602,"user_tz":-330,"elapsed":6,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1aedddec-0b4c-4d83-d4a3-f59606082990"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total Real Videos: 588\n","Total Fake Videos: 5634\n"]}]},{"cell_type":"code","source":["# real_count = 0\n","# valid_real_videos= []\n","# valid_fake_videos= []\n","\n","# def valid_video_list(video_files, train_transforms, valid_videos):\n","#     for video_path in tqdm(video_files):\n","#         try:\n","#             validate_video(video_path, train_transforms)\n","#             video_name = os.path.basename(video_path)\n","#             valid_videos.append(video_name)\n","#         except:\n","#             continue\n","\n","\n","# valid_video_list(real_videos, train_transforms, valid_real_videos)\n","# valid_video_list(fake_videos, train_transforms, valid_fake_videos)\n","\n","# print(f\"Valid real videos: {len(valid_real_videos)}\")\n","# print(f\"Valid fake videos: {len(valid_fake_videos)}\")"],"metadata":{"id":"Ij-cqmly3ZA3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# RUN FROM HERE"],"metadata":{"id":"pUGl4bAI_gGg"}},{"cell_type":"code","source":["# Paths where you want to save\n","save_real_path = \"/content/drive/My Drive/celeb_df_face_cropped/valid_real_videos.json\"\n","save_fake_path = \"/content/drive/My Drive/celeb_df_face_cropped/valid_fake_videos.json\"\n"],"metadata":{"id":"OTWfmsIS7hH3","executionInfo":{"status":"ok","timestamp":1754369715705,"user_tz":-330,"elapsed":41,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Already Saved -----> DO NOT TOUCH\n","\n","# # Save lists\n","# with open(save_real_path, 'w') as f:\n","#     json.dump(valid_real_videos, f)\n","\n","# with open(save_fake_path, 'w') as f:\n","#     json.dump(valid_fake_videos, f)\n","\n","# print(\"Lists saved successfully.\")"],"metadata":{"id":"Kqwx-paZ7-ef","executionInfo":{"status":"ok","timestamp":1754369717341,"user_tz":-330,"elapsed":10,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Load lists from JSON\n","valid_real_videos = []\n","valid_fake_videos = []\n","\n","with open(save_real_path, 'r') as f:\n","    valid_real_videos = json.load(f)\n","\n","with open(save_fake_path, 'r') as f:\n","    valid_fake_videos = json.load(f)\n","\n","# Paths to real and fake video folders on Google Drive\n","celeb_df_real_path = '/content/drive/My Drive/celeb_df_face_cropped/real_face_only224'\n","celeb_df_fake_path = '/content/drive/My Drive/celeb_df_face_cropped/fake_face_only224'\n","\n","# Reconstruct full paths\n","valid_real_videos_path = [os.path.join(celeb_df_real_path, name) for name in valid_real_videos]\n","valid_fake_videos_path = [os.path.join(celeb_df_fake_path, name) for name in valid_fake_videos]\n","\n","print(f\"Total real videos for training: {len(valid_real_videos_path)}\")\n","print(f\"Total fake videos for training: {len(valid_fake_videos_path)}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GI-cAiFN717w","executionInfo":{"status":"ok","timestamp":1754369722870,"user_tz":-330,"elapsed":16,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"outputId":"848dd6af-6ab0-411b-80e2-91657f683d15"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Total real videos for training: 587\n","Total fake videos for training: 5635\n"]}]},{"cell_type":"code","source":["valid_real_videos_path[0]\n","valid_fake_videos_path[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"sTAfZhes_yaw","executionInfo":{"status":"ok","timestamp":1754369725357,"user_tz":-330,"elapsed":12,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"outputId":"43d35361-2290-4029-a0eb-d75c39fe2c18"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/celeb_df_face_cropped/fake_face_only224/id0_id16_0000.mp4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["torch.manual_seed(42)\n","random.seed(42)\n","np.random.seed(42)"],"metadata":{"id":"yMeoUzyDASrP","executionInfo":{"status":"ok","timestamp":1754369726942,"user_tz":-330,"elapsed":7,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class DeepFakeDataset(Dataset):\n","    def __init__(self, video_paths, labels, transform=None, num_frames=16):\n","        self.video_paths = video_paths\n","        self.labels = labels\n","        self.transform = transform\n","        self.num_frames = num_frames\n","\n","    def read_frames(self, video_path):\n","        cap = cv2.VideoCapture(video_path)\n","        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        frame_indices = np.linspace(0, total_frames - 1, self.num_frames).astype(int)   #\n","        frames = []\n","\n","        for idx in frame_indices:\n","            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n","            ret, frame = cap.read()\n","            if not ret:\n","                continue\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            if self.transform:\n","                frame = self.transform(image=frame)['image']\n","            frames.append(frame)\n","\n","        cap.release()\n","\n","        if len(frames) < self.num_frames:\n","            # pad missing frames with black images\n","            for _ in range(self.num_frames - len(frames)):\n","                frames.append(torch.zeros_like(frames[0]))\n","\n","        return torch.stack(frames)\n","\n","    def __len__(self):\n","        return len(self.video_paths)\n","\n","    def __getitem__(self, idx):\n","        try:\n","            video_tensor = self.read_frames(self.video_paths[idx])\n","            label = torch.tensor(self.labels[idx], dtype=torch.float32)\n","            return video_tensor, label\n","        except Exception as e:\n","            print(f\"Failed loading video: {self.video_paths[idx]}, Error: {e}\")\n","            return self.__getitem__((idx + 1) % len(self))"],"metadata":{"id":"tTDR2bTU8JII","executionInfo":{"status":"ok","timestamp":1754369728720,"user_tz":-330,"elapsed":7,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# DATA TRANSFORMS\n","transform = A.Compose([\n","    A.Resize(224, 224),\n","    A.Normalize(),\n","    ToTensorV2(),\n","])"],"metadata":{"id":"7d9b-gfe8LM_","executionInfo":{"status":"ok","timestamp":1754369730840,"user_tz":-330,"elapsed":10,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Combine video paths and labels\n","video_paths = valid_real_videos_path + valid_fake_videos_path\n","labels = [0]*len(valid_real_videos_path) + [1]*len(valid_fake_videos_path)\n","\n","# Use train_test_split to shuffle and split\n","train_paths, val_paths, train_labels, val_labels = train_test_split(\n","    video_paths, labels, test_size=0.2, stratify=labels, random_state=10\n",")\n","\n","# Create datasets and loaders\n","train_dataset = DeepFakeDataset(train_paths, train_labels, transform)\n","val_dataset = DeepFakeDataset(val_paths, val_labels, transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2, pin_memory=True)\n"],"metadata":{"id":"cAImvVUl8NfA","executionInfo":{"status":"ok","timestamp":1754369732370,"user_tz":-330,"elapsed":9,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# MODEL COMPONENTS\n","class TemporalAttention(nn.Module):\n","    def __init__(self, feature_dim):\n","        super().__init__()\n","        self.attention = nn.Linear(feature_dim, 1)\n","\n","    def forward(self, x):\n","        # x: (batch, time, features)\n","        weights = F.softmax(self.attention(x), dim=1)\n","        return torch.sum(weights * x, dim=1)\n","\n","\n","class DeepFakeDetector(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.feature_extractor = EfficientNet.from_pretrained('efficientnet-b0')\n","        self.feature_extractor._fc = nn.Identity()\n","        self.lstm = nn.LSTM(input_size=1280, hidden_size=256, num_layers=1, batch_first=True, bidirectional=True)\n","        self.attention = TemporalAttention(512)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 1)\n","        )\n","\n","    def forward(self, x):\n","        B, T, C, H, W = x.shape\n","        x = x.view(B*T, C, H, W)\n","        with torch.no_grad():  # freeze feature extractor to reduce memory\n","            feats = self.feature_extractor(x)\n","        feats = feats.view(B, T, -1)\n","        lstm_out, _ = self.lstm(feats)\n","        attn_out = self.attention(lstm_out)\n","        return self.classifier(attn_out).squeeze(1)\n"],"metadata":{"id":"HL5JB4ex8Ruw","executionInfo":{"status":"ok","timestamp":1754369734525,"user_tz":-330,"elapsed":10,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, dataloader, optimizer, criterion, device):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","\n","    loop = tqdm(dataloader, desc=\"Training\", leave=False)\n","    for inputs, labels in loop:\n","        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        preds = (torch.sigmoid(outputs) > 0.5).float()\n","        correct += (preds == labels).sum().item()\n","        running_loss += loss.item() * inputs.size(0)\n","\n","    epoch_loss = running_loss / len(dataloader.dataset)\n","    epoch_acc = correct / len(dataloader.dataset)\n","    return epoch_loss, epoch_acc\n","\n","\n","def validate(model, dataloader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","\n","    loop = tqdm(dataloader, desc=\"Validation\", leave=False)\n","    with torch.no_grad():\n","        for inputs, labels in loop:\n","            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            preds = (torch.sigmoid(outputs) > 0.5).float()\n","            correct += (preds == labels).sum().item()\n","            running_loss += loss.item() * inputs.size(0)\n","\n","    epoch_loss = running_loss / len(dataloader.dataset)\n","    epoch_acc = correct / len(dataloader.dataset)\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"nHBMRBoA8ae-","executionInfo":{"status":"ok","timestamp":1754369737050,"user_tz":-330,"elapsed":11,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# START TRAINING\n","model = DeepFakeDetector().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","criterion = nn.BCEWithLogitsLoss()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBXfjJsC8bVH","executionInfo":{"status":"ok","timestamp":1754369740382,"user_tz":-330,"elapsed":878,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"outputId":"a7cf2759-0683-4a0f-87c2-6cf72d227cd9"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b0\n"]}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ZcppIf_x8gff","executionInfo":{"status":"ok","timestamp":1754369744547,"user_tz":-330,"elapsed":42,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"outputId":"80d1aa7b-08a5-4ddc-d5ca-45a2a2ddc07e"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeepFakeDetector(\n","  (feature_extractor): EfficientNet(\n","    (_conv_stem): Conv2dStaticSamePadding(\n","      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n","      (static_padding): ZeroPad2d((0, 1, 0, 1))\n","    )\n","    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    (_blocks): ModuleList(\n","      (0): MBConvBlock(\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n","          (static_padding): ZeroPad2d((1, 1, 1, 1))\n","        )\n","        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          32, 8, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          8, 32, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (1): MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n","          (static_padding): ZeroPad2d((0, 1, 0, 1))\n","        )\n","        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          96, 4, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          4, 96, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (2): MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n","          (static_padding): ZeroPad2d((1, 1, 1, 1))\n","        )\n","        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          144, 6, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          6, 144, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (3): MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n","          (static_padding): ZeroPad2d((1, 2, 1, 2))\n","        )\n","        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          144, 6, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          6, 144, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (4): MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n","          (static_padding): ZeroPad2d((2, 2, 2, 2))\n","        )\n","        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          240, 10, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          10, 240, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (5): MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n","          (static_padding): ZeroPad2d((0, 1, 0, 1))\n","        )\n","        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          240, 10, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          10, 240, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (6-7): 2 x MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n","          (static_padding): ZeroPad2d((1, 1, 1, 1))\n","        )\n","        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          480, 20, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          20, 480, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (8): MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n","          (static_padding): ZeroPad2d((2, 2, 2, 2))\n","        )\n","        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          480, 20, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          20, 480, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (9-10): 2 x MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n","          (static_padding): ZeroPad2d((2, 2, 2, 2))\n","        )\n","        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          672, 28, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          28, 672, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (11): MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n","          (static_padding): ZeroPad2d((1, 2, 1, 2))\n","        )\n","        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          672, 28, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          28, 672, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (12-14): 3 x MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n","          (static_padding): ZeroPad2d((2, 2, 2, 2))\n","        )\n","        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","      (15): MBConvBlock(\n","        (_expand_conv): Conv2dStaticSamePadding(\n","          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_depthwise_conv): Conv2dStaticSamePadding(\n","          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n","          (static_padding): ZeroPad2d((1, 1, 1, 1))\n","        )\n","        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_se_reduce): Conv2dStaticSamePadding(\n","          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_se_expand): Conv2dStaticSamePadding(\n","          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n","          (static_padding): Identity()\n","        )\n","        (_project_conv): Conv2dStaticSamePadding(\n","          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n","          (static_padding): Identity()\n","        )\n","        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","        (_swish): MemoryEfficientSwish()\n","      )\n","    )\n","    (_conv_head): Conv2dStaticSamePadding(\n","      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n","      (static_padding): Identity()\n","    )\n","    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n","    (_dropout): Dropout(p=0.2, inplace=False)\n","    (_fc): Identity()\n","    (_swish): MemoryEfficientSwish()\n","  )\n","  (lstm): LSTM(1280, 256, batch_first=True, bidirectional=True)\n","  (attention): TemporalAttention(\n","    (attention): Linear(in_features=512, out_features=1, bias=True)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=512, out_features=128, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.3, inplace=False)\n","    (3): Linear(in_features=128, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# Prepare save path\n","model_dir = '/content/drive/My Drive/trained_model'\n","os.makedirs(model_dir, exist_ok=True)\n","save_path = os.path.join(model_dir, 'best_model_celeb_df.pth')\n","\n","# Training loop\n","EPOCHS = 5\n","best_val_acc = 0.0\n","\n","for epoch in range(EPOCHS):\n","    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n","\n","    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n","    val_loss, val_acc = validate(model, val_loader, criterion, device)\n","\n","    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n","    print(f\"Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n","\n","    # Save best model\n","    if val_acc > best_val_acc:\n","        best_val_acc = val_acc\n","        torch.save({\n","            'epoch': epoch + 1,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'val_accuracy': best_val_acc\n","        }, save_path)\n","        print(f\"ðŸ’¾ Model saved to Google Drive with Val Accuracy: {best_val_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ui9gESLH80w3","executionInfo":{"status":"ok","timestamp":1754373496912,"user_tz":-330,"elapsed":3747606,"user":{"displayName":"Deepfake Detection 2026","userId":"15224683282243019540"}},"outputId":"16239e1d-790d-4abd-b8cc-b5e951b8fab0"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["\rTraining:   0%|          | 0/2489 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/fake_face_only224/id56_id54_0003.mp4, Error: list index out of range\n","Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/fake_face_only224/id55_id58_0007.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  29%|â–ˆâ–ˆâ–‰       | 180/623 [01:33<04:08,  1.78it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/real_face_only224/id1_0003.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 394/623 [03:28<02:04,  1.83it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/fake_face_only224/id31_id6_0001.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.3091, Accuracy: 0.9050\n","Val   Loss: 0.2378, Accuracy: 0.9084\n","ðŸ’¾ Model saved to Google Drive with Val Accuracy: 0.9084\n","\n","Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  28%|â–ˆâ–ˆâ–Š       | 177/623 [00:28<01:05,  6.79it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/real_face_only224/id1_0003.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 395/623 [01:04<00:47,  4.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/fake_face_only224/id31_id6_0001.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.2641, Accuracy: 0.9076\n","Val   Loss: 0.2263, Accuracy: 0.9229\n","ðŸ’¾ Model saved to Google Drive with Val Accuracy: 0.9229\n","\n","Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  28%|â–ˆâ–ˆâ–Š       | 177/623 [00:29<01:15,  5.92it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/real_face_only224/id1_0003.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 395/623 [01:04<00:33,  6.75it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/fake_face_only224/id31_id6_0001.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.2483, Accuracy: 0.9098\n","Val   Loss: 0.2197, Accuracy: 0.9293\n","ðŸ’¾ Model saved to Google Drive with Val Accuracy: 0.9293\n","\n","Epoch 4/5\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  28%|â–ˆâ–ˆâ–Š       | 177/623 [00:29<01:14,  5.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/real_face_only224/id1_0003.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 395/623 [01:05<00:33,  6.81it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/fake_face_only224/id31_id6_0001.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.2349, Accuracy: 0.9154\n","Val   Loss: 0.2171, Accuracy: 0.9317\n","ðŸ’¾ Model saved to Google Drive with Val Accuracy: 0.9317\n","\n","Epoch 5/5\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  29%|â–ˆâ–ˆâ–Š       | 178/623 [00:28<01:05,  6.77it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/real_face_only224/id1_0003.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":["Validation:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 394/623 [01:02<00:32,  6.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Failed loading video: /content/drive/My Drive/celeb_df_face_cropped/fake_face_only224/id31_id6_0001.mp4, Error: list index out of range\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.2321, Accuracy: 0.9182\n","Val   Loss: 0.2058, Accuracy: 0.9333\n","ðŸ’¾ Model saved to Google Drive with Val Accuracy: 0.9333\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"q7dm3O_DlLsM"},"execution_count":null,"outputs":[]}]}