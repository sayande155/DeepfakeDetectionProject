{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4871436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "\n",
    "import glob\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef8a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = glob.glob(\"D:/Desktop/Final Year Project/DataSets/data_preprocessing/celeb_df/fake_face_only224/*mp4\")\n",
    "video_files += glob.glob(\"D:/Desktop/Final Year Project/DataSets/data_preprocessing/celeb_df/real_face_only224/*mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ea60e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Videos : 6228\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Videos : {len(video_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f45c8fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_extract(path):\n",
    "    video = cv2.VideoCapture(path)\n",
    "    success = True\n",
    "    while success:\n",
    "        success, image = video.read()\n",
    "        if success:\n",
    "            yield image\n",
    "\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67aa55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate video by trying to extract and transform 20 frames.\n",
    "\n",
    "import random\n",
    "\n",
    "def validate_video(video_path, transform, count=20):\n",
    "    all_frames = [frame for frame in frame_extract(video_path) if frame is not None]\n",
    "\n",
    "    if len(all_frames) < count:\n",
    "        raise ValueError(f\"Not enough frames in video: {video_path} (Found {len(all_frames)})\")\n",
    "\n",
    "    selected_frames = random.sample(all_frames, count)\n",
    "\n",
    "    transformed_frames = [transform(frame) for frame in selected_frames]\n",
    "    frames_tensor = torch.stack(transformed_frames)\n",
    "\n",
    "    return frames_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d127d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "image_size = 224\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0778f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8766ae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 119/6228 [00:03<02:40, 38.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in video D:/Desktop/Final Year Project/DataSets/data_preprocessing/celeb_df/fake_face_only224\\id10_id11_0001.mp4\n",
      "Error in video D:/Desktop/Final Year Project/DataSets/data_preprocessing/celeb_df/fake_face_only224\\id10_id12_0001.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 138/6228 [00:04<02:33, 39.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in video D:/Desktop/Final Year Project/DataSets/data_preprocessing/celeb_df/fake_face_only224\\id10_id13_0001.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 143/6228 [00:04<02:30, 40.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in video D:/Desktop/Final Year Project/DataSets/data_preprocessing/celeb_df/fake_face_only224\\id10_id7_0001.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 5659/6228 [02:15<00:12, 44.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in video D:/Desktop/Final Year Project/DataSets/data_preprocessing/celeb_df/real_face_only224\\id10_0001.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 6173/6228 [02:27<00:01, 45.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in video D:/Desktop/Final Year Project/DataSets/data_preprocessing/celeb_df/real_face_only224\\id5_0008.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6228/6228 [02:28<00:00, 41.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid : 6222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "valid_videos= []\n",
    "for i in tqdm(video_files):\n",
    "    try : \n",
    "        validate_video(i, train_transforms)\n",
    "        valid_videos.append(i)\n",
    "        count += 1\n",
    "    except : \n",
    "        print(f\"Error in video {i}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Valid : {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
